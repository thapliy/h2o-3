package hex.tree.gbm;

import hex.ModelMetricsBinomial;
import hex.SplitFrame;
import hex.VarImp;
import ml.dmlc.xgboost4j.java.Booster;
import ml.dmlc.xgboost4j.java.DMatrix;
import ml.dmlc.xgboost4j.java.XGBoost;
import ml.dmlc.xgboost4j.java.XGBoostError;
import org.junit.BeforeClass;
import org.junit.Test;
import water.*;
import water.api.schemas3.VarImpV3;
import water.fvec.Frame;
import water.fvec.Vec;
import water.util.ArrayUtils;
import water.util.FrameUtils;
import water.util.Log;

import java.io.*;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Map;

public class XGBoostTest extends TestUtil {

  @BeforeClass public static void stall() { stall_till_cloudsize(1); }

  static DMatrix[] getMatrices() throws XGBoostError {
    // load file from text file, also binary buffer generated by xgboost4j
    return new DMatrix[]{
       new DMatrix("../xgboost/demo/data/agaricus.txt.train"),
       new DMatrix("../xgboost/demo/data/agaricus.txt.test")
    };
  }

  static void saveDumpModel(String modelPath, String[] modelInfos) throws IOException {
    try{
      PrintWriter writer = new PrintWriter(modelPath, "UTF-8");
      for(int i = 0; i < modelInfos.length; ++ i) {
        writer.print("booster[" + i + "]:\n");
        writer.print(modelInfos[i]);
      }
      writer.close();
    } catch (Exception e) {
      e.printStackTrace();
    }
  }

  static boolean checkPredicts(float[][] fPredicts, float[][] sPredicts) {
    if (fPredicts.length != sPredicts.length) {
      return false;
    }

    for (int i = 0; i < fPredicts.length; i++) {
      if (!Arrays.equals(fPredicts[i], sPredicts[i])) {
        return false;
      }
    }

    return true;
  }

  @Test
  public void testMatrices() throws XGBoostError { getMatrices(); }

  @Test
  public void BasicModel() throws XGBoostError {
    // load file from text file, also binary buffer generated by xgboost4j
    DMatrix[] mat = getMatrices();
    DMatrix trainMat = mat[0];
    DMatrix testMat = mat[1];

    HashMap<String, Object> params = new HashMap<>();
    params.put("eta", 0.1);
    params.put("max_depth", 5);
    params.put("silent", 1);
    params.put("objective", "binary:logistic");

    HashMap<String, DMatrix> watches = new HashMap<>();
    watches.put("train", trainMat);
    watches.put("test",  testMat);

    Booster booster = XGBoost.train(trainMat, params, 10, watches, null, null);
    float[][] preds = booster.predict(testMat);
    for (int i=0;i<10;++i)
      Log.info(preds[i][0]);
  }

  @Test
  public void saveLoadDataAndModel() throws XGBoostError, IOException {
    // load file from text file, also binary buffer generated by xgboost4j
    DMatrix[] mat = getMatrices();
    DMatrix trainMat = mat[0];
    DMatrix testMat = mat[1];

    HashMap<String, Object> params = new HashMap<>();
    params.put("eta", 0.1);
    params.put("max_depth", 5);
    params.put("silent", 1);
    params.put("objective", "binary:logistic");

    HashMap<String, DMatrix> watches = new HashMap<>();
    watches.put("train", trainMat);
    watches.put("test",  testMat);

    Booster booster = XGBoost.train(trainMat, params, 10, watches, null, null);

    float[][] predicts = booster.predict(testMat);

    //save model to modelPath
    File file = new File("./model");
    if (!file.exists()) {
      file.mkdirs();
    }

    String modelPath = "./model/xgb.model";
    booster.saveModel(modelPath);

    //dump model with feature map
    String[] modelInfos = booster.getModelDump("../xgboost/demo/data/featmap.txt", false);
    saveDumpModel("./model/dump.raw.txt", modelInfos);

    //save dmatrix into binary buffer
    testMat.saveBinary("./model/dtest.buffer");

    //reload model and data
    Booster booster2 = XGBoost.loadModel("./model/xgb.model");
    DMatrix testMat2 = new DMatrix("./model/dtest.buffer");
    float[][] predicts2 = booster2.predict(testMat2);

    //check the two predicts
    System.out.println(checkPredicts(predicts, predicts2));

    //specify watchList
    HashMap<String, DMatrix> watches2 = new HashMap<>();
    watches2.put("train", trainMat);
    watches2.put("test", testMat2);
    Booster booster3 = XGBoost.train(trainMat, params, 10, watches2, null, null);
    float[][] predicts3 = booster3.predict(testMat2);

    //check predicts
    System.out.println(checkPredicts(predicts, predicts3));
  }

  @Test
  public void checkpoint() throws XGBoostError, IOException {
    // load file from text file, also binary buffer generated by xgboost4j
    DMatrix[] mat = getMatrices();
    DMatrix trainMat = mat[0];
    DMatrix testMat = mat[1];

    HashMap<String, Object> params = new HashMap<>();
    params.put("eta", 0.1);
    params.put("max_depth", 5);
    params.put("silent", 1);
    params.put("objective", "binary:logistic");

    HashMap<String, DMatrix> watches = new HashMap<>();
    watches.put("train", trainMat);

    Booster booster = XGBoost.train(trainMat, params, 0, watches, null, null);

    // Train for 10 iterations
    for (int i=0;i<10;++i) {
      booster.update(trainMat, i);
      float[][] preds = booster.predict(testMat);
      for (int j = 0; j < 10; ++j)
        Log.info(preds[j][0]);
    }
  }

  static DMatrix convertFrametoDMatrix(Frame f, String response, String weight, String fold, String[] featureMap) throws XGBoostError {
    // one-hot encoding
    FrameUtils.CategoricalOneHotEncoder enc = new FrameUtils.CategoricalOneHotEncoder(f, new String[]{response, weight, fold});
    Frame encoded = enc.exec().get();
    long denseLen = encoded.numRows()*(encoded.numCols() - 1 /*response*/);
    if (denseLen > (1<<28)) throw new IllegalArgumentException("Too many matrix elements.");
    if (encoded.numRows() > (1<<28)) throw new IllegalArgumentException("Too many rows.");

    if (featureMap!=null) {
      StringBuilder sb = new StringBuilder();
      for (int i = 0; i < encoded.numCols(); ++i) {
        sb.append(i).append(" ").append(encoded.name(i)).append(" ");
        if (encoded.vec(i).isBinary()) sb.append("i");
        else if (encoded.vec(i).isInt()) sb.append("int");
        else sb.append("q");
        sb.append("\n");
      }
      featureMap[0] = sb.toString();
    }


    // convert to CSC sparse matrix
    // example matrix:
    // 1 0 2 0
    // 4 0 0 3
    // 3 1 2 0
//    long[] colHeaders = new long[] {0,        3,  4,     6,    7}; //offsets
//    float[] data = new float[]     {1f,4f,3f, 1f, 2f,2f, 3f};      //non-zeros down each column
//    int[] rowIndex = new int[]     {0,1,2,    2,  0, 2,  1};       //row index for each non-zero
    long[] colHeaders = new long[encoded.numCols() - 1 /*response*/ + 1 /*final offset*/];
    float[] data   = new float[(int)denseLen];
    int[] rowIndex = new int[(int)denseLen];

    // extract predictors
    int nz=0;
    int col=0;
    for (int i=0;i<encoded.numCols();++i) {
      if (encoded.name(i).equals(response)) continue;

      colHeaders[col] = nz;
      Vec.Reader v = encoded.vec(i).new Reader();
      for (int j=0;j<v.length();++j) {
        double val = v.at(j);
        if (!Double.isNaN(val) && val!=0) {
          data[nz] = (float)val;
          rowIndex[nz] = j;
          nz++;
        }
      }
      col++;
    }
    // extract response vector
    Vec.Reader respVec = encoded.vec(response).new Reader();
    int nRows = (int)respVec.length();
    float[] resp = new float[nRows];
    for (int i=0;i<nRows;++i)
      resp[i] = (float)respVec.at(i);

    colHeaders[colHeaders.length-1] = nz;
    data = Arrays.copyOf(data, nz);
    rowIndex = Arrays.copyOf(rowIndex, nz);

    DMatrix trainMat = new DMatrix(colHeaders, rowIndex, data, DMatrix.SparseType.CSC, 0);
    trainMat.setLabel(resp);
//    trainMat.setWeight(null); //obs weight //FIXME
//    trainMat.setGroup(null); //fold
    encoded.remove();
    return trainMat;
  }

  @Test
  public void H2OFrame() throws XGBoostError, IOException {
    Frame tfr = null;
    Frame trainFrame = null;
    Frame testFrame = null;
    try {
      // Parse frame into H2O
      tfr = parse_test_file("./smalldata/junit/weather.csv");
      // remove columns correlated with the response
      tfr.remove("RISK_MM").remove();
      tfr.remove("EvapMM").remove();
      DKV.put(tfr);

      // split into train/test
      SplitFrame sf = new SplitFrame(tfr, new double[] { 0.7, 0.3 }, null);
      sf.exec().get();
      Key[] ksplits = sf._destination_frames;
      trainFrame = (Frame)ksplits[0].get();
      testFrame = (Frame)ksplits[1].get();

      // define special columns
      String response = "RainTomorrow";
      String weight = null;
      String fold = null;

      // create sparse DMatrices
      String[] featureMap = new String[]{""};
      DMatrix trainMat = convertFrametoDMatrix(trainFrame, response, weight, fold, featureMap);
      DMatrix testMat = convertFrametoDMatrix(testFrame, response, weight, fold, null);

      // set parameters
      HashMap<String, Object> params = new HashMap<>();
      params.put("eta", 0.1);
      params.put("max_depth", 5);
      params.put("silent", 1);
      params.put("objective", "binary:logistic");

      HashMap<String, DMatrix> watches = new HashMap<>();
      watches.put("test", testMat);

      Booster booster = XGBoost.train(trainMat, params, 0, watches, null, null);

      OutputStream os = new FileOutputStream("featureMap.txt");
      os.write(featureMap[0].getBytes());
      os.close();

      int ntree = 10;
      for (int i = 0; i < ntree; ++i) {
        // train
        booster.update(trainMat, i);

        // compute model metrics on test set
        float[][] preds = booster.predict(testMat);
        double[] dpreds = new double[preds.length];
        for (int j = 0; j < dpreds.length; ++j)
          dpreds[j] = preds[j][0];
        Vec pred = Vec.makeVec(dpreds, Vec.newKey());
        ModelMetricsBinomial mm = ModelMetricsBinomial.make(pred, testFrame.vec(response));
        Log.info(mm);
        pred.remove();

        // compute variable importance
        Map<String, Integer> varimp = booster.getFeatureScore("featureMap.txt");
        float[] viFloat = new float[varimp.size()];
        String[] names = new String[varimp.size()];
        int j=0;
        for (Map.Entry<String, Integer> it : varimp.entrySet()) {
          viFloat[j] = it.getValue();
          names[j] = it.getKey();
          j++;
        }
        VarImp vi = new VarImp(viFloat, names);
      }
    } finally {
      if (trainFrame!=null) trainFrame.remove();
      if (testFrame!=null) testFrame.remove();
      if (tfr!=null) tfr.remove();
    }
  }

}
